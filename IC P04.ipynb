{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTree Classifer Demonstration\n",
    "\n",
    "In this tutorial we will demonstrate how to use the `DecisionTreeClassifer` class in `scikit-learn` to perform classifications predictions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Setup\n",
    "Import modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Load data\n",
    "Load data (it's already cleaned and preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following snippet of code to debug problems with finding the .csv file path\n",
    "# This snippet of code will exit the program and print the current working directory.\n",
    "#import os\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('airbnb_train_X_price_gte_150.csv') \n",
    "y_train = pd.read_csv('airbnb_train_y_price_gte_150.csv') \n",
    "X_test = pd.read_csv('airbnb_test_X_price_gte_150.csv') \n",
    "y_test = pd.read_csv('airbnb_test_y_price_gte_150.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['price_gte_150'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The best precision score is 0.9370404920282969\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 0.01, 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.1,1,10,143],\n",
    "    'gamma':[1,0.01,0.001,0.0001],\n",
    "    'kernel':['poly']\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SVM_R_out = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = SVM_R_out, param_distributions=param_grid, cv=kfolds, n_iter=16,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The best precision score is 0.9370404920282969\n",
      "... with parameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "#grid search in SVM\n",
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.1,1,10,143],\n",
    "    'gamma':[1,0.01,0.001,0.0001],\n",
    "    'kernel':['poly']\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SVM_G_out = SVC()\n",
    "grid_search = GridSearchCV(estimator = SVM_G_out, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct an initial random search across a wide range of possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best precision score is 0.8506202419854265\n",
      "... with parameters: {'min_samples_split': 8, 'min_samples_leaf': 22, 'min_impurity_decrease': 0.001, 'max_leaf_nodes': 11, 'max_depth': 9, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,24),  \n",
    "    'min_samples_leaf': np.arange(1,24),\n",
    "    'min_impurity_decrease': np.arange(0.001, 0.1, 0.005),\n",
    "    'max_leaf_nodes': np.arange(6, 24), \n",
    "    'max_depth': np.arange(6,24), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct an exhaustive search across a smaller range of parameters around the parameters found in the initial random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n",
      "The best precision score is 0.8330433636237797\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 35, 'max_leaf_nodes': 35, 'min_impurity_decrease': 0.009, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,7),  \n",
    "    'min_samples_leaf': np.arange(2,5),\n",
    "    'min_impurity_decrease': np.arange(0.009, 0.012,0.001),\n",
    "    'max_leaf_nodes': np.arange(35,39), \n",
    "    'max_depth': np.arange(35,39), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the four models evaluated, the SVM model using polynomial kernel and random search with k-folds = 5 and C values in the specified range achieved a precision of 0.93. Similarly, the SVM model using the same k-fold and C values but with grid search also achieved a precision of 0.93. These two SVM models outperformed the decision tree models using random and grid search, which had precision scores of 0.85 and 0.83, respectively. Thus, the SVM models were found to be the most suitable models while the decision tree models were the least suitable for the given problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
